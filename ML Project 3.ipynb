{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5835611-93bc-452e-a9ca-54b189779c55",
   "metadata": {},
   "source": [
    "# AML Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370fb95-5015-4292-b837-9165bb9c9afa",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b30385-151a-40bf-8685-89e4a1c3d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3679a-3b89-44ed-81b4-9e7540929e1f",
   "metadata": {},
   "source": [
    "# Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7250ce2-aaba-4283-bd04-8c0583428fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['age_group'] = pd.cut(\n",
    "        df['Age'], bins=[0, 18, 30, 45, 60, 75, 120],\n",
    "        labels=['Child', 'YoungAdult', 'Adult', 'Midlife', 'Senior', 'Elder']\n",
    "    )\n",
    "    \n",
    "    df['bmi_category'] = pd.cut(\n",
    "        df['BMI'], bins=[0, 18.5, 25, 30, 35, 100],\n",
    "        labels=['Underweight', 'Normal', 'Overweight', 'Obese', 'SeverelyObese']\n",
    "    )\n",
    "\n",
    "    df['hypertension'] = ((df['Systolic'] > 130) | (df['Diastolic'] > 80)).astype(int)\n",
    "    df['hypertension_cat'] = pd.cut(\n",
    "        df['Systolic'], bins=[0, 120, 130, 140, 180],\n",
    "        labels=['Normal', 'Elevated', 'Stage1', 'Stage2']\n",
    "    )\n",
    "\n",
    "    df['chol_ratio'] = df['HDL'] / (df['TCHOL'] + 1e-6)\n",
    "    df['ldl_hdl_ratio'] = df['LDL'] / (df['HDL'] + 1e-6)\n",
    "    df['tchol_hdl_ratio'] = df['TCHOL'] / (df['HDL'] + 1e-6)\n",
    "    df['non_hdl_chol'] = df['TCHOL'] - df['HDL']\n",
    "\n",
    "    df['pulse_pressure'] = df['Systolic'] - df['Diastolic']\n",
    "\n",
    "    df['diabetes_bin'] = (df['Diabetes'] == 1).astype(int)\n",
    "    df['diabetes_cat'] = df['Diabetes'].map({0: 'No', 1: 'Yes', 2: 'Borderline'}).astype('category')\n",
    "\n",
    "    df['smoker_bin'] = df['CurrentSmoker'].map({0: 0, 1: 1}).fillna(0).astype(int)\n",
    "    df['smoker_cat'] = df['CurrentSmoker'].map({0: 'No', 1: 'Yes', 2: 'Unknown'}).astype('category')\n",
    "\n",
    "    if 'Insurance' in df.columns:\n",
    "        df['Insurance'] = df['Insurance'].astype('category')\n",
    "    if 'Race' in df.columns:\n",
    "        df['Race'] = df['Race'].astype('category')\n",
    "\n",
    "    df['age_bmi'] = df['Age'] * df['BMI']\n",
    "    df['bmi_ldl'] = df['BMI'] * df['LDL']\n",
    "    df['bp_bmi'] = (df['Systolic'] + df['Diastolic']) * df['BMI']\n",
    "    df['hdl_ldl_ratio'] = df['HDL'] / (df['LDL'] + 1e-6)\n",
    "    df['income_edu'] = df['Income'] * df['Edu']\n",
    "    df['age_systolic'] = df['Age'] * df['Systolic']\n",
    "    df['bmi_hdl'] = df['BMI'] * df['HDL']\n",
    "    df['pulse_bmi'] = df['Pulse'] * df['BMI']\n",
    "    df['age_tchol'] = df['Age'] * df['TCHOL']\n",
    "    df['bmi_tchol'] = df['BMI'] * df['TCHOL']\n",
    "    df['age_diastolic'] = df['Age'] * df['Diastolic']\n",
    "    df['bmi_diastolic'] = df['BMI'] * df['Diastolic']\n",
    "    df['age_pulse'] = df['Age'] * df['Pulse']\n",
    "    df['bmi_pulse'] = df['BMI'] * df['Pulse']\n",
    "    df['systolic_diastolic_ratio'] = df['Systolic'] / (df['Diastolic'] + 1e-6)\n",
    "    df['tchol_ldl_ratio'] = df['TCHOL'] / (df['LDL'] + 1e-6)\n",
    "    df['trig_hdl_ratio'] = df['Trig'] / (df['HDL'] + 1e-6)\n",
    "    df['trig_ldl_ratio'] = df['Trig'] / (df['LDL'] + 1e-6)\n",
    "    df['trig_tchol_ratio'] = df['Trig'] / (df['TCHOL'] + 1e-6)\n",
    "\n",
    "    # Missing value indicators\n",
    "    for col in ['Systolic', 'Diastolic', 'HDL', 'LDL', 'TCHOL']:\n",
    "        df[f'is_{col.lower()}_missing'] = df[col].isnull().astype(int)\n",
    "\n",
    "    numeric_cols = ['BMI', 'HDL', 'LDL', 'TCHOL', 'Trig', 'Pulse', 'eGFP',\n",
    "                    'Systolic', 'Diastolic', 'Age', 'Income']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col + '_norm'] = (df[col] - df[col].mean()) / (df[col].std() + 1e-6)\n",
    "\n",
    "    # Clip extreme ratios\n",
    "    ratio_cols = [c for c in df.columns if \"ratio\" in c]\n",
    "    df[ratio_cols] = df[ratio_cols].clip(-10, 10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return engineer_features(X)\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        missing_ratio = X.isnull().mean()\n",
    "        self.cols_to_drop_ = missing_ratio[missing_ratio > 0.3].index.tolist()\n",
    "\n",
    "        X_tmp = X.drop(columns=self.cols_to_drop_, errors=\"ignore\")\n",
    "        numeric_cols = X_tmp.select_dtypes(include=np.number).columns\n",
    "        categorical_cols = X_tmp.select_dtypes(include=\"object\").columns\n",
    "\n",
    "        self.numeric_means_ = X_tmp[numeric_cols].mean()\n",
    "        self.categorical_modes_ = X_tmp[categorical_cols].mode().iloc[0] if len(categorical_cols) > 0 else pd.Series(dtype=\"object\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns=self.cols_to_drop_, errors=\"ignore\").copy()\n",
    "        X = X.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "\n",
    "        # Fill numeric missing values\n",
    "        for col, mean in self.numeric_means_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna(mean)\n",
    "\n",
    "        # Fill categorical missing values\n",
    "        for col, mode in self.categorical_modes_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna(mode)\n",
    "\n",
    "        return pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb738a-e830-4e27-8725-35ad334544be",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5f0851-9358-4249-b98c-06e7edccb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"P2_data_stroke_train.csv\")\n",
    "df = df.dropna(subset=[\"stroke\"]).copy()\n",
    "df[\"stroke\"] = df[\"stroke\"].replace({2: 0}).astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"stroke\"])\n",
    "y = df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f71c32-408f-4680-8b12-b1def7b227f5",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5761740-3f61-4601-8b60-196b4cd62568",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "fe = FeatureEngineer()\n",
    "X_train_fe = fe.fit_transform(X_train)\n",
    "X_test_fe = fe.transform(X_test)\n",
    "\n",
    "numeric_cols = X_train_fe.select_dtypes(include=np.number).columns\n",
    "for col in numeric_cols:\n",
    "    X_train_fe[col] = X_train_fe[col].fillna(X_train_fe[col].mean())\n",
    "    X_test_fe[col] = X_test_fe[col].fillna(X_train_fe[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b306b-a000-4134-8eec-6c1475947802",
   "metadata": {},
   "source": [
    "# Preprocessing And Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac7fd8f-db11-43c8-be76-a9069f6a4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_steps = [\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", Preprocessor()),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"selector\", SelectKBest(score_func=f_classif, k=40))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ca334-9a1a-4402-a137-1e1c02b6beb9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c2d128-e79f-4e45-9f28-ddaab07bc783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression\n",
      "\n",
      "Logistic Regression Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      2632\n",
      "           1       0.11      0.88      0.20       108\n",
      "\n",
      "    accuracy                           0.72      2740\n",
      "   macro avg       0.55      0.80      0.52      2740\n",
      "weighted avg       0.96      0.72      0.81      2740\n",
      "\n",
      "Log Loss: 0.5305291100220426\n",
      "[[1882  750]\n",
      " [  13   95]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "log_reg_pipeline = ImbPipeline(\n",
    "    steps=common_steps + [\n",
    "\n",
    "        (\"classifier\", LogisticRegression(\n",
    "            max_iter=1000, \n",
    "            solver='liblinear', \n",
    "            class_weight='balanced',\n",
    "            penalty='l1',\n",
    "            C=0.4\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training Logistic Regression\")\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred_log = log_reg_pipeline.predict(X_test)\n",
    "y_prob_log = log_reg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nLogistic Regression Results\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_prob_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1d46c-87fa-48d2-84e6-579103d0199f",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699462a9-ce26-4b0f-8ad0-c16be55d44d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest\n",
      "\n",
      "Random Forest Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      2632\n",
      "           1       0.11      0.78      0.19       108\n",
      "\n",
      "    accuracy                           0.74      2740\n",
      "   macro avg       0.55      0.76      0.52      2740\n",
      "weighted avg       0.95      0.74      0.82      2740\n",
      "\n",
      "Log Loss: 0.4269119998222432\n",
      "[[1950  682]\n",
      " [  24   84]]\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline = ImbPipeline(\n",
    "    steps=common_steps + [\n",
    "        (\"classifier\", RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=6,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "y_prob_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nRandom Forest Results\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_prob_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d645fa2-f07f-42cb-8e0a-b01e6d3c2c3e",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da68adb2-48e9-4144-bba1-b4204ff9bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM\n",
      "\n",
      "SVM Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      2632\n",
      "           1       0.11      0.75      0.19       108\n",
      "\n",
      "    accuracy                           0.75      2740\n",
      "   macro avg       0.55      0.75      0.52      2740\n",
      "weighted avg       0.95      0.75      0.82      2740\n",
      "\n",
      "Log Loss: 0.46949616079651163\n",
      "[[1968  664]\n",
      " [  27   81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "svm = SVC(\n",
    "        kernel='poly',\n",
    "        C=0.05,\n",
    "        gamma='scale',\n",
    "        class_weight='balanced',\n",
    "        probability=True,\n",
    "        random_state=42\n",
    ")\n",
    "\n",
    "calibrated_svm = CalibratedClassifierCV(svm, method='sigmoid', cv=5)\n",
    "\n",
    "svm_pipeline = ImbPipeline(steps=common_steps + [(\"smote\", SMOTE(random_state=42)), (\"classifier\", calibrated_svm)])\n",
    "\n",
    "print(\"\\nTraining SVM\")\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "y_prob_svm = svm_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nSVM Results\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_prob_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716a441-e17f-464c-bc27-6add58f18a24",
   "metadata": {},
   "source": [
    "# Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07ed945-4245-4c18-824b-7ef0ee225fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating stroke probabilities for test data\n",
      "\n",
      "Output saved\n",
      "   Participant ID  Logistic regression prediction  Random forest prediction  \\\n",
      "0             101                            0.37                      0.49   \n",
      "1             102                            0.49                      0.57   \n",
      "2             103                            0.34                      0.26   \n",
      "3             104                            0.11                      0.08   \n",
      "4             105                            0.69                      0.71   \n",
      "\n",
      "   SVM prediction  \n",
      "0            0.65  \n",
      "1            0.69  \n",
      "2            0.22  \n",
      "3            0.04  \n",
      "4            0.78  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"P2_data_stroke_test.csv\")\n",
    "test_ids = test_df[\"Participant ID\"].copy()\n",
    "\n",
    "print(\"\\nGenerating stroke probabilities for test data\")\n",
    "\n",
    "if 'stroke' in test_df.columns:\n",
    "    test_df = test_df.drop('stroke', axis=1)\n",
    "\n",
    "y_prob_log_test = log_reg_pipeline.predict_proba(test_df)[:, 1]\n",
    "y_prob_rf_test = rf_pipeline.predict_proba(test_df)[:, 1]\n",
    "y_prob_svm_test = svm_pipeline.predict_proba(test_df)[:, 1]\n",
    "\n",
    "output = pd.DataFrame({\n",
    "    \"Participant ID\": test_ids,\n",
    "    \"Logistic regression prediction\": y_prob_log_test,\n",
    "    \"Random forest prediction\": y_prob_rf_test,\n",
    "    \"SVM prediction\": y_prob_svm_test\n",
    "})\n",
    "\n",
    "# Round probabilities to 2 decimal places\n",
    "output = output.round({\n",
    "    \"Logistic regression prediction\": 2,\n",
    "    \"Random forest prediction\": 2,\n",
    "    \"SVM prediction\": 2\n",
    "})\n",
    "\n",
    "# Save to file\n",
    "output.to_csv(\"stroke_probabilities.csv\", index=False)\n",
    "\n",
    "print(\"\\nOutput saved\")\n",
    "print(output.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
